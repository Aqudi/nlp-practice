{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 딥 러닝을 이용한 자연어 처리 입문\r\n",
    "\r\n",
    "아래 링크의 E-book을 보고 실습한 내용입니다.\r\n",
    "\r\n",
    "WikiDocs 주소: https://wikidocs.net/31766\r\n",
    "\r\n",
    "\r\n",
    "# 5장 카운트 기반의 단어 표현\r\n",
    "\r\n",
    "## 2절 여러가지 유사도 기법 (유클리드 거리, 자카드 유사도)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 유클리드 거리 구하기\r\n",
    "\r\n",
    "문서 간의 유클리드 거리가 가까울 수록 유사하다고 볼 수 있다.\r\n",
    "\r\n",
    "예제의 결과로 docQ와 가장 가까운 문서는 doc1이라고 볼 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "def dist(x, y):\r\n",
    "    \"\"\"유클리드 거리 구하는 함수\"\"\"\r\n",
    "    return np.sqrt(np.sum((x-y) ** 2))\r\n",
    "\r\n",
    "doc1 = np.array([2, 3, 0, 1])\r\n",
    "doc2 = np.array([1, 2, 3, 1])\r\n",
    "doc3 = np.array([2, 1, 2, 2])\r\n",
    "\r\n",
    "# 거리를 비교할 대상\r\n",
    "docQ = np.array([1, 1, 0, 1])\r\n",
    "\r\n",
    "print(dist(doc1, docQ))\r\n",
    "print(dist(doc2, docQ))\r\n",
    "print(dist(doc3, docQ))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.23606797749979\n",
      "3.1622776601683795\n",
      "2.449489742783178\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 자카드 유사도\r\n",
    "\r\n",
    "$$J(A,B)=\\frac{|A \\cap B|}{|A \\cup B} = \\frac{|A \\cap B|}{|A| + |B| - |A \\cap B|}$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "doc1 = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Praesent et.\"\r\n",
    "doc2 = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Mauris efficitur.\"\r\n",
    "\r\n",
    "# 토큰화\r\n",
    "tokenized_doc1 = doc1.lower().split()\r\n",
    "tokenized_doc2 = doc2.lower().split()\r\n",
    "\r\n",
    "# 토큰화 결과\r\n",
    "print(\"doc1:\", tokenized_doc1)\r\n",
    "print(\"doc2:\", tokenized_doc2)\r\n",
    "\r\n",
    "# 집합 자료형으로 바꾸기\r\n",
    "tokenized_doc1 = set(tokenized_doc1)\r\n",
    "tokenized_doc2 = set(tokenized_doc2)\r\n",
    "\r\n",
    "# 교집합, 합집합 구하기\r\n",
    "union = tokenized_doc1.union(tokenized_doc2)\r\n",
    "intersection = tokenized_doc1.intersection(tokenized_doc2)\r\n",
    "print(\"\\n합집합:\", union)\r\n",
    "print(\"교집합:\", intersection)\r\n",
    "\r\n",
    "\r\n",
    "# 자카드 유사도 구하기\r\n",
    "print(\"\\n자카드 유사도:\", len(intersection) / len(union))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "doc1: ['lorem', 'ipsum', 'dolor', 'sit', 'amet,', 'consectetur', 'adipiscing', 'elit.', 'praesent', 'et.']\n",
      "doc2: ['lorem', 'ipsum', 'dolor', 'sit', 'amet,', 'consectetur', 'adipiscing', 'elit.', 'mauris', 'efficitur.']\n",
      "\n",
      "합집합: {'lorem', 'efficitur.', 'elit.', 'amet,', 'dolor', 'consectetur', 'mauris', 'praesent', 'ipsum', 'et.', 'adipiscing', 'sit'}\n",
      "교집합: {'lorem', 'elit.', 'ipsum', 'amet,', 'dolor', 'consectetur', 'adipiscing', 'sit'}\n",
      "\n",
      "자카드 유사도: 0.6666666666666666\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 자카드 유사도 구하기"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "bb9f406c0f70fca9801e60f2cbb7cd1ccff2ae2f74c58f513340bcf6cae5ecd0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}