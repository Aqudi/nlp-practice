{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥 러닝을 이용한 자연어 처리 입문\n",
    "\n",
    "아래 링크의 E-book을 보고 실습한 내용입니다.\n",
    "\n",
    "WikiDocs 주소: https://wikidocs.net/31766\n",
    "\n",
    "# 7장 머신 러닝 개요\n",
    "\n",
    "## 4절 자동 미분과 선형 회귀 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 식 $2w^2 + 5$을 $w$에 대하여 미분하는 예제\n",
    "\n",
    "### Tensorflow 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# tf.Variable을 이용하여 학습 가능한 파라미터 w 선언\n",
    "w = tf.Variable(2.)\n",
    "\n",
    "# 파라미터 w를 이용하여 식 f(w) = 2w^2 + 5 표현\n",
    "def f(w):\n",
    "    y = w ** 2\n",
    "    z = 2*y + 5\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>]\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GradientTape을 활용하여 w에 미분값이 저장되었음을 확인\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w)\n",
    "\n",
    "gradients = tape.gradient(z, [w])\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설 함수 출력 결과: [ 5.  7. 13. 25. 41. 19.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n가설 함수 출력 결과: [ 5.  7. 13. 25. 41. 19.]\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의의 가중치와 편향 선언\n",
    "W = tf.Variable(4.0)\n",
    "b = tf.Variable(1.0)\n",
    "\n",
    "\n",
    "# 가설 함수 선언\n",
    "@tf.function\n",
    "def hypothesis(x):\n",
    "    return W*x + b\n",
    "\n",
    "\n",
    "x_test = [1, 1.5, 3, 6, 10, 4.5]\n",
    "print(f\"가설 함수 출력 결과: {hypothesis(x_test).numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 | W: 8.2133 | b: 1.664 | cost: 1402.555542\n",
      "epoch:  10 | W: 10.4971 | b: 1.977 | cost: 1.351182\n",
      "epoch:  20 | W: 10.5047 | b:  1.93 | cost: 1.328165\n",
      "epoch:  30 | W: 10.5119 | b: 1.884 | cost: 1.306967\n",
      "epoch:  40 | W: 10.5188 | b: 1.841 | cost: 1.287436\n",
      "epoch:  50 | W: 10.5254 | b: 1.799 | cost: 1.269459\n",
      "epoch:  60 | W: 10.5318 | b: 1.759 | cost: 1.252898\n",
      "epoch:  70 | W: 10.5379 | b: 1.721 | cost: 1.237644\n",
      "epoch:  80 | W: 10.5438 | b: 1.684 | cost: 1.223598\n",
      "epoch:  90 | W: 10.5494 | b: 1.648 | cost: 1.210658\n",
      "epoch: 100 | W: 10.5548 | b: 1.614 | cost: 1.198740\n",
      "epoch: 110 | W: 10.5600 | b: 1.582 | cost: 1.187767\n",
      "epoch: 120 | W: 10.5650 | b:  1.55 | cost: 1.177665\n",
      "epoch: 130 | W: 10.5697 | b:  1.52 | cost: 1.168354\n",
      "epoch: 140 | W: 10.5743 | b: 1.492 | cost: 1.159782\n",
      "epoch: 150 | W: 10.5787 | b: 1.464 | cost: 1.151890\n",
      "epoch: 160 | W: 10.5829 | b: 1.437 | cost: 1.144619\n",
      "epoch: 170 | W: 10.5870 | b: 1.412 | cost: 1.137924\n",
      "epoch: 180 | W: 10.5909 | b: 1.387 | cost: 1.131752\n",
      "epoch: 190 | W: 10.5946 | b: 1.364 | cost: 1.126073\n",
      "epoch: 200 | W: 10.5982 | b: 1.341 | cost: 1.120843\n",
      "epoch: 210 | W: 10.6016 | b:  1.32 | cost: 1.116026\n",
      "epoch: 220 | W: 10.6049 | b: 1.299 | cost: 1.111589\n",
      "epoch: 230 | W: 10.6081 | b: 1.279 | cost: 1.107504\n",
      "epoch: 240 | W: 10.6111 | b:  1.26 | cost: 1.103736\n",
      "epoch: 250 | W: 10.6140 | b: 1.242 | cost: 1.100273\n",
      "epoch: 260 | W: 10.6168 | b: 1.224 | cost: 1.097082\n",
      "epoch: 270 | W: 10.6195 | b: 1.207 | cost: 1.094143\n",
      "epoch: 280 | W: 10.6221 | b: 1.191 | cost: 1.091434\n",
      "epoch: 290 | W: 10.6245 | b: 1.176 | cost: 1.088940\n",
      "epoch: 300 | W: 10.6269 | b: 1.161 | cost: 1.086645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nepoch:   0 | W: 8.2133 | b: 1.664 | cost: 1402.555542\\nepoch:  10 | W: 10.4971 | b: 1.977 | cost: 1.351182\\nepoch:  20 | W: 10.5047 | b:  1.93 | cost: 1.328165\\n... (중략)\\nepoch: 280 | W: 10.6221 | b: 1.191 | cost: 1.091434\\nepoch: 290 | W: 10.6245 | b: 1.176 | cost: 1.088940\\nepoch: 300 | W: 10.6269 | b: 1.161 | cost: 1.086645\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE 함수\n",
    "@tf.function\n",
    "def mse_loss(y_pred, y):\n",
    "    # (예측값 - 실제값)^2 의 평균\n",
    "    return tf.reduce_mean(tf.square(y_pred - y))\n",
    "\n",
    "\n",
    "X = [1, 2, 3, 4, 5, 6, 7, 8, 9]  # 공부하는 시간\n",
    "y = [11, 22, 33, 44, 53, 66, 77, 87, 95]  # 각 공부하는 시간에 맵핑되는 성적\n",
    "\n",
    "# 최적화 알고리즘: 경사 하강법, 학습률 0.01\n",
    "optimizer = tf.optimizers.SGD(0.01)\n",
    "\n",
    "# 학습 진행\n",
    "for i in range(301):\n",
    "\t\t# 계산 과정 GradientTape에 기록\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = hypothesis(X)\n",
    "        cost = mse_loss(y_pred, y)\n",
    "\t\t# 오류 역전파 알고리즘을 통해 오차에 대한 미분값 계산\n",
    "    gradients = tape.gradient(cost, [W, b])\n",
    "\t\t# 학습 가능한 파라미터들에 계산된 미분값 적용\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"epoch: {i:3} | W: {W.numpy():5.4f} | b: {b.numpy():5.4} | cost: {cost:5.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임의의 입력에 대한 출력: [38.35479  54.295143 59.608593 64.92204 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n임의의 입력에 대한 출력: [38.35479  54.295143 59.608593 64.92204 ]\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의의 값을 넣어 출력되는 결과 확인\n",
    "x_test = [3.5, 5, 5.5, 6]\n",
    "print(\"임의의 입력에 대한 출력:\", hypothesis(x_test).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4836.7876 - mse: 4836.7876\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 596.2854 - mse: 596.2854\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 74.5215 - mse: 74.5215\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 10.3205 - mse: 10.3205\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 989us/step - loss: 2.4192 - mse: 2.4192\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4453 - mse: 1.4453\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3236 - mse: 1.3236\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.3069 - mse: 1.3069\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3031 - mse: 1.3031\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 992us/step - loss: 1.3008 - mse: 1.3008\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.2988 - mse: 1.2988\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2969 - mse: 1.2969\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2949 - mse: 1.2949\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2930 - mse: 1.2930\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2911 - mse: 1.2911\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2892 - mse: 1.2892\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2873 - mse: 1.2873\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2855 - mse: 1.2855\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.2836 - mse: 1.2836\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2818 - mse: 1.2818\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2800 - mse: 1.2800\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2782 - mse: 1.2782\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2764 - mse: 1.2764\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2746 - mse: 1.2746\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2728 - mse: 1.2728\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2711 - mse: 1.2711\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.2694 - mse: 1.2694\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.2676 - mse: 1.2676\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2659 - mse: 1.2659\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2642 - mse: 1.2642\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.2626 - mse: 1.2626\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.2609 - mse: 1.2609\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2593 - mse: 1.2593\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2576 - mse: 1.2576\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2560 - mse: 1.2560\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2544 - mse: 1.2544\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2528 - mse: 1.2528\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2512 - mse: 1.2512\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2496 - mse: 1.2496\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2481 - mse: 1.2481\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 988us/step - loss: 1.2465 - mse: 1.2465\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2450 - mse: 1.2450\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2435 - mse: 1.2435\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2420 - mse: 1.2420\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2405 - mse: 1.2405\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 988us/step - loss: 1.2390 - mse: 1.2390\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2376 - mse: 1.2376\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2361 - mse: 1.2361\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.2347 - mse: 1.2347\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2332 - mse: 1.2332\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.2318 - mse: 1.2318\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2304 - mse: 1.2304\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 996us/step - loss: 1.2290 - mse: 1.2290\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2276 - mse: 1.2276\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 990us/step - loss: 1.2262 - mse: 1.2262\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2249 - mse: 1.2249\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2235 - mse: 1.2235\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2222 - mse: 1.2222\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2208 - mse: 1.2208\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 969us/step - loss: 1.2195 - mse: 1.2195\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2182 - mse: 1.2182\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2169 - mse: 1.2169\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.2156 - mse: 1.2156\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2144 - mse: 1.2144\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.2131 - mse: 1.2131\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 997us/step - loss: 1.2118 - mse: 1.2118\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.2106 - mse: 1.2106\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2093 - mse: 1.2093\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2081 - mse: 1.2081\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2069 - mse: 1.2069\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2057 - mse: 1.2057\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2045 - mse: 1.2045\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2033 - mse: 1.2033\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2021 - mse: 1.2021\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2010 - mse: 1.2010\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1998 - mse: 1.1998\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1987 - mse: 1.1987\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1975 - mse: 1.1975\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1964 - mse: 1.1964\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1953 - mse: 1.1953\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1942 - mse: 1.1942\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1931 - mse: 1.1931\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1920 - mse: 1.1920\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 986us/step - loss: 1.1909 - mse: 1.1909\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1898 - mse: 1.1898\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1888 - mse: 1.1888\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1877 - mse: 1.1877\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1867 - mse: 1.1867\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1856 - mse: 1.1856\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1846 - mse: 1.1846\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1836 - mse: 1.1836\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1826 - mse: 1.1826\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1815 - mse: 1.1815\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1805 - mse: 1.1805\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1796 - mse: 1.1796\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1786 - mse: 1.1786\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1776 - mse: 1.1776\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 988us/step - loss: 1.1766 - mse: 1.1766\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1757 - mse: 1.1757\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1747 - mse: 1.1747\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1738 - mse: 1.1738\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1729 - mse: 1.1729\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1719 - mse: 1.1719\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1710 - mse: 1.1710\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1701 - mse: 1.1701\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1692 - mse: 1.1692\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1683 - mse: 1.1683\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1674 - mse: 1.1674\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1665 - mse: 1.1665\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1657 - mse: 1.1657\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1648 - mse: 1.1648\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1639 - mse: 1.1639\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1631 - mse: 1.1631\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1622 - mse: 1.1622\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1614 - mse: 1.1614\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1606 - mse: 1.1606\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1597 - mse: 1.1597\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1589 - mse: 1.1589\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1581 - mse: 1.1581\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1573 - mse: 1.1573\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1565 - mse: 1.1565\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1557 - mse: 1.1557\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1549 - mse: 1.1549\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1541 - mse: 1.1541\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1534 - mse: 1.1534\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1526 - mse: 1.1526\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1518 - mse: 1.1518\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1511 - mse: 1.1511\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1503 - mse: 1.1503\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1496 - mse: 1.1496\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1489 - mse: 1.1489\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1481 - mse: 1.1481\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1474 - mse: 1.1474\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1467 - mse: 1.1467\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1460 - mse: 1.1460\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1453 - mse: 1.1453\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1446 - mse: 1.1446\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1439 - mse: 1.1439\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1432 - mse: 1.1432\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1425 - mse: 1.1425\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1418 - mse: 1.1418\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1412 - mse: 1.1412\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1405 - mse: 1.1405\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1398 - mse: 1.1398\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1392 - mse: 1.1392\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1385 - mse: 1.1385\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1379 - mse: 1.1379\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1372 - mse: 1.1372\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1366 - mse: 1.1366\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1360 - mse: 1.1360\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1354 - mse: 1.1354\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1347 - mse: 1.1347\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1341 - mse: 1.1341\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1335 - mse: 1.1335\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1329 - mse: 1.1329\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1323 - mse: 1.1323\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1317 - mse: 1.1317\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1311 - mse: 1.1311\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1305 - mse: 1.1305\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1300 - mse: 1.1300\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1294 - mse: 1.1294\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1288 - mse: 1.1288\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1283 - mse: 1.1283\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1277 - mse: 1.1277\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1271 - mse: 1.1271\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1266 - mse: 1.1266\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 989us/step - loss: 1.1260 - mse: 1.1260\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1255 - mse: 1.1255\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1250 - mse: 1.1250\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1244 - mse: 1.1244\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1239 - mse: 1.1239\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1234 - mse: 1.1234\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1229 - mse: 1.1229\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1223 - mse: 1.1223\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1218 - mse: 1.1218\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 992us/step - loss: 1.1213 - mse: 1.1213\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1208 - mse: 1.1208\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1203 - mse: 1.1203\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1198 - mse: 1.1198\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1193 - mse: 1.1193\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1188 - mse: 1.1188\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1184 - mse: 1.1184\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1179 - mse: 1.1179\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1174 - mse: 1.1174\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1169 - mse: 1.1169\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1165 - mse: 1.1165\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1160 - mse: 1.1160\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1155 - mse: 1.1155\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1151 - mse: 1.1151\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1146 - mse: 1.1146\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1142 - mse: 1.1142\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1137 - mse: 1.1137\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1133 - mse: 1.1133\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1129 - mse: 1.1129\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1124 - mse: 1.1124\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1120 - mse: 1.1120\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1116 - mse: 1.1116\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1111 - mse: 1.1111\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1107 - mse: 1.1107\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1103 - mse: 1.1103\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1099 - mse: 1.1099\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1095 - mse: 1.1095\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1091 - mse: 1.1091\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1087 - mse: 1.1087\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1083 - mse: 1.1083\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1079 - mse: 1.1079\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1075 - mse: 1.1075\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1071 - mse: 1.1071\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1067 - mse: 1.1067\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1063 - mse: 1.1063\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 987us/step - loss: 1.1059 - mse: 1.1059\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1056 - mse: 1.1056\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1052 - mse: 1.1052\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1048 - mse: 1.1048\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1044 - mse: 1.1044\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1041 - mse: 1.1041\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1037 - mse: 1.1037\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1034 - mse: 1.1034\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1030 - mse: 1.1030\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1027 - mse: 1.1027\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1023 - mse: 1.1023\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 997us/step - loss: 1.1019 - mse: 1.1019\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1016 - mse: 1.1016\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1013 - mse: 1.1013\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1009 - mse: 1.1009\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1006 - mse: 1.1006\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1003 - mse: 1.1003\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0999 - mse: 1.0999\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0996 - mse: 1.0996\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0993 - mse: 1.0993\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0989 - mse: 1.0989\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0986 - mse: 1.0986\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0983 - mse: 1.0983\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0980 - mse: 1.0980\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.0977 - mse: 1.0977\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0974 - mse: 1.0974\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0971 - mse: 1.0971\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0968 - mse: 1.0968\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0965 - mse: 1.0965\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0962 - mse: 1.0962\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0959 - mse: 1.0959\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0956 - mse: 1.0956\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0953 - mse: 1.0953\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0950 - mse: 1.0950\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0947 - mse: 1.0947\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0944 - mse: 1.0944\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0941 - mse: 1.0941\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0938 - mse: 1.0938\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0936 - mse: 1.0936\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0933 - mse: 1.0933\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0930 - mse: 1.0930\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0927 - mse: 1.0927\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 989us/step - loss: 1.0925 - mse: 1.0925\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0922 - mse: 1.0922\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.0919 - mse: 1.0919\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0917 - mse: 1.0917\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0914 - mse: 1.0914\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0912 - mse: 1.0912\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0909 - mse: 1.0909\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0906 - mse: 1.0906\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.0904 - mse: 1.0904\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0901 - mse: 1.0901\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0899 - mse: 1.0899\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0897 - mse: 1.0897\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.0894 - mse: 1.0894\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0892 - mse: 1.0892\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0889 - mse: 1.0889\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0887 - mse: 1.0887\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0885 - mse: 1.0885\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0882 - mse: 1.0882\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0880 - mse: 1.0880\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0878 - mse: 1.0878\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0875 - mse: 1.0875\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0873 - mse: 1.0873\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0871 - mse: 1.0871\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0868 - mse: 1.0868\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0866 - mse: 1.0866\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0864 - mse: 1.0864\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0862 - mse: 1.0862\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0860 - mse: 1.0860\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0858 - mse: 1.0858\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0856 - mse: 1.0856\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.0853 - mse: 1.0853\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0851 - mse: 1.0851\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0849 - mse: 1.0849\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0847 - mse: 1.0847\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0845 - mse: 1.0845\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0843 - mse: 1.0843\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0841 - mse: 1.0841\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.0839 - mse: 1.0839\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0837 - mse: 1.0837\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.0835 - mse: 1.0835\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0833 - mse: 1.0833\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0831 - mse: 1.0831\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0829 - mse: 1.0829\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0828 - mse: 1.0828\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0826 - mse: 1.0826\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0824 - mse: 1.0824\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0822 - mse: 1.0822\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0820 - mse: 1.0820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEpoch 1/300\\n1/1 [==============================] - 0s 2ms/step - loss: 4480.4175 - mse: 4480.4175\\nEpoch 2/300\\n1/1 [==============================] - 0s 1ms/step - loss: 552.4086 - mse: 552.4086\\nEpoch 3/300\\n1/1 [==============================] - 0s 998us/step - loss: 69.0947 - mse: 69.0947\\n...(중략)\\n1/1 [==============================] - 0s 1ms/step - loss: 1.0796 - mse: 1.0796\\nEpoch 299/300\\n1/1 [==============================] - 0s 1ms/step - loss: 1.0794 - mse: 1.0794\\nEpoch 300/300\\n1/1 [==============================] - 0s 1ms/step - loss: 1.0792 - mse: 1.0792\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "X = [1, 2, 3, 4, 5, 6, 7, 8, 9] # 공부하는 시간\n",
    "y = [11, 22, 33, 44, 53, 66, 77, 87, 95] # 각 공부하는 시간에 맵핑되는 성적\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 입, 출력 차원이 1인 선형 레이어를 만들어준다.\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "\n",
    "# 학습률 0.01로 optimizer SGD를 선언해준다.\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "\n",
    "# 비용 함수로는 MSE를 사용한다.\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
    "\n",
    "# 학습 진행\n",
    "model.fit(X, y, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x254e361dbb0>,\n",
       " <matplotlib.lines.Line2D at 0x254e361dc10>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습된 모델이 그리는 최적화된 직선\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X, model.predict(X), 'b', X, y, 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: [[102.1326]]\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터에 없던 데이터 예측\n",
    "print(\"예측값:\", model.predict([9.5]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "131a2fe7960016a5e2629e09f3ca62b0c2ece83e5ed32d3907f8ac9bf090694a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('tf': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
